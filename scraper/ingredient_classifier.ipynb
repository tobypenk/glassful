{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.Corpus import Corpus\n",
    "from model.Model import Model\n",
    "from model.Embeddings import Embeddings\n",
    "\n",
    "# Dimensions in the GloVe embedding\n",
    "embedding_dim = 100\n",
    "# Enforced max and min length of an example\n",
    "max_length = 60\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "num_epochs = 10\n",
    "training_size = 89500\n",
    "test_portion = .1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(\n",
    "    \"training_data/augmented_classified_ingredients.csv\",\n",
    "    training_size,\n",
    "    max_length,\n",
    "    padding_type,\n",
    "    trunc_type,\n",
    "    test_portion\n",
    ").initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embeddings(\n",
    "    \"glove.6B.100d.txt\",\n",
    "    embedding_dim,\n",
    "    corpus\n",
    ").activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2518/2518 [==============================] - 74s 30ms/step - loss: 1.4310 - accuracy: 0.7160 - val_loss: 0.1901 - val_accuracy: 0.9515\n",
      "Epoch 2/10\n",
      "2518/2518 [==============================] - 78s 31ms/step - loss: 0.2000 - accuracy: 0.9468 - val_loss: 0.0896 - val_accuracy: 0.9725\n",
      "Epoch 3/10\n",
      "2518/2518 [==============================] - 77s 30ms/step - loss: 0.1280 - accuracy: 0.9626 - val_loss: 0.0669 - val_accuracy: 0.9781\n",
      "Epoch 4/10\n",
      "2518/2518 [==============================] - 76s 30ms/step - loss: 0.1011 - accuracy: 0.9688 - val_loss: 0.0553 - val_accuracy: 0.9823\n",
      "Epoch 5/10\n",
      "2518/2518 [==============================] - 75s 30ms/step - loss: 0.0905 - accuracy: 0.9715 - val_loss: 0.0596 - val_accuracy: 0.9800\n",
      "Epoch 6/10\n",
      "2518/2518 [==============================] - 75s 30ms/step - loss: 0.0840 - accuracy: 0.9721 - val_loss: 0.0546 - val_accuracy: 0.9819\n",
      "Epoch 7/10\n",
      "2518/2518 [==============================] - 75s 30ms/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.0504 - val_accuracy: 0.9840\n",
      "Epoch 8/10\n",
      "2518/2518 [==============================] - 74s 30ms/step - loss: 0.0709 - accuracy: 0.9763 - val_loss: 0.0493 - val_accuracy: 0.9839\n",
      "Epoch 9/10\n",
      "2518/2518 [==============================] - 74s 30ms/step - loss: 0.0694 - accuracy: 0.9770 - val_loss: 0.0488 - val_accuracy: 0.9846\n",
      "Epoch 10/10\n",
      "2518/2518 [==============================] - 77s 30ms/step - loss: 0.0674 - accuracy: 0.9773 - val_loss: 0.0539 - val_accuracy: 0.9827\n"
     ]
    }
   ],
   "source": [
    "classifier = Model(\n",
    "    corpus,\n",
    "    embeddings,\n",
    "    max_length,\n",
    "    num_epochs,\n",
    "    1190\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "39\n",
      "180\n",
      "27\n",
      "76\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "tst_snt = [\n",
    "     '2 ounces  gin',\n",
    "      '3/4 ounce  lemon juice',\n",
    "      '1/2 ounce  simple syrup or maple syrup',\n",
    "      '1 egg white*',\n",
    "      'Garnish with lemon twist',\n",
    "      'Soda water'\n",
    "]\n",
    "tst_snt = corpus.tokenizer.texts_to_sequences(tst_snt)\n",
    "tst_snt = pad_sequences(tst_snt, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
    "pred = classifier.model.predict(tst_snt)\n",
    "\n",
    "for fc in pred:\n",
    "    print(np.argmax(fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "corp = pd.read_csv(\n",
    "    \"training_data/ingredients_with_ids.csv\", \n",
    "    encoding=\"latin-1\",\n",
    "    header=\"\"\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "corp = []\n",
    "with open(\"training_data/ingredients_with_ids.csv\", errors='ignore') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        corp.append(row)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
