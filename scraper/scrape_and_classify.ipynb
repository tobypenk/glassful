{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.Corpus import Corpus\n",
    "from model.Model import Model\n",
    "from model.Embeddings import Embeddings\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "import csv\n",
    "from scrapers.ScraperResult import ScraperResult\n",
    "from page_processors import *\n",
    "\n",
    "global_hyperparameters = {\n",
    "    \"embedding_dim\": 100, # Dimensions in the GloVe embedding\n",
    "    \"max_length\": 60, # Enforced max and min character length of an example\n",
    "    \"trunc_type\": \"post\",\n",
    "    \"padding_type\": \"post\",\n",
    "    \"oov_tok\": \"<OOV>\",\n",
    "    \"test_portion\": 0.1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should tokenize the labels; there aren't 1191 unique ones\n",
    "\n",
    "ingredients_hyperparameters = {\n",
    "    \"num_epochs\": 6,\n",
    "    \"training_size\": 89500\n",
    "}\n",
    "\n",
    "ingredient_corpus = Corpus(\n",
    "    \"training_data/augmented_classified_ingredients.csv\",\n",
    "    global_hyperparameters,\n",
    "    ingredients_hyperparameters\n",
    ").initialize()\n",
    "\n",
    "ingredient_embeddings = Embeddings(\n",
    "    \"glove.6B.100d.txt\",\n",
    "    ingredient_corpus,\n",
    "    global_hyperparameters\n",
    ").activate()\n",
    "\n",
    "ingredient_classifier = Model(\n",
    "    ingredient_corpus,\n",
    "    ingredient_embeddings,\n",
    "    global_hyperparameters,\n",
    "    ingredients_hyperparameters,\n",
    "    1191\n",
    ").run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_hyperparameters = {\n",
    "    \"num_epochs\": 4,\n",
    "    \"training_size\": 76000\n",
    "}\n",
    "\n",
    "recipe_corpus = Corpus(\n",
    "    \"training_data/augmented_training_labels.csv\",\n",
    "    global_hyperparameters,\n",
    "    recipes_hyperparameters\n",
    ").initialize()\n",
    "\n",
    "recipe_embeddings = Embeddings(\n",
    "    \"glove.6B.100d.txt\",\n",
    "    recipe_corpus,\n",
    "    global_hyperparameters\n",
    ").activate()\n",
    "\n",
    "recipe_classifier = Model(\n",
    "    recipe_corpus,\n",
    "    recipe_embeddings,\n",
    "    global_hyperparameters,\n",
    "    recipes_hyperparameters,\n",
    "    5\n",
    ").run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapers.PageProcessor import PageProcessor\n",
    "from model.Cache import Cache\n",
    "instance_cache = Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_payload = []\n",
    "\n",
    "new_links = [\n",
    "    \"https://www.bbcgoodfood.com/recipes/espresso-martini\",\n",
    "    \"https://www.seriouseats.com/the-martini-recipe\"\n",
    "]\n",
    "\n",
    "with open('newlabels.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    for link in new_links:\n",
    "        print(link)\n",
    "        \n",
    "        #try:\n",
    "        data = PageProcessor(\n",
    "            link,\n",
    "            recipe_classifier,\n",
    "            recipe_corpus,\n",
    "            global_hyperparameters,\n",
    "            writer\n",
    "        )\n",
    "        data.soupify()\n",
    "        this_recipe = ScraperResult(\n",
    "            link.split(\"/\")[-1],\n",
    "            list(map(lambda x: x[0], lasso_inward(data.classifications,4,1,1,2)[0])),\n",
    "            list(map(lambda x: x[0], lasso_inward(data.classifications,4,1,2,2)[0])),\n",
    "            list(map(lambda x: x[0], lasso_inward(data.classifications,4,1,3,2)[0])),\n",
    "            list(map(lambda x: x[0], lasso_inward(data.classifications,4,1,4,2)[0]))\n",
    "        )\n",
    "        this_recipe.map_payload_ingredients(\n",
    "            instance_cache.get_ingredients(),\n",
    "            ingredient_corpus,\n",
    "            ingredient_classifier,\n",
    "            global_hyperparameters\n",
    "        )\n",
    "        total_payload.append(this_recipe.get_payload())\n",
    "\n",
    "        #except:\n",
    "        #    print(\"link \" + link + \" could not be opened\")\n",
    "\n",
    "\n",
    "pprint(total_payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_page(\n",
    "    \"https://www.seriouseats.com/the-martini-recipe\",\n",
    "    #writer,\n",
    "    recipe_classifier,\n",
    "    recipe_corpus,\n",
    "    global_hyperparameters[\"max_length\"],\n",
    "    global_hyperparameters[\"padding_type\"],\n",
    "    global_hyperparameters[\"trunc_type\"]\n",
    ")\n",
    "this_recipe = ScraperResult(\n",
    "    link.split(\"/\")[-1],\n",
    "    list(map(lambda x: x[0], lasso_inward(data,4,6,1,7)[0])),\n",
    "    list(map(lambda x: x[0], lasso_inward(data,4,6,2,7)[0])),\n",
    "    list(map(lambda x: x[0], lasso_inward(data,4,6,3,7)[0])),\n",
    "    list(map(lambda x: x[0], lasso_inward(data,4,6,4,7)[0]))\n",
    ")\n",
    "this_payload = this_recipe.get_payload()\n",
    "this_payload_mapped = this_recipe.map_payload_ingredients(\n",
    "    instance_cache.get_ingredients(),\n",
    "    ingredient_corpus,\n",
    "    ingredient_classifier,\n",
    "    global_hyperparameters\n",
    ")\n",
    "total_payload.append(this_recipe.get_payload())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(this_payload_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_snt = total_payload[0][\"ingredients\"]\n",
    "tst_snt = ingredient_corpus.tokenizer.texts_to_sequences(tst_snt)\n",
    "tst_snt = pad_sequences(\n",
    "    tst_snt, \n",
    "    maxlen=global_hyperparameters[\"max_length\"], \n",
    "    padding=global_hyperparameters[\"padding_type\"], \n",
    "    truncating=global_hyperparameters[\"trunc_type\"]\n",
    ")\n",
    "pred = ingredient_classifier.model.predict(tst_snt)\n",
    "\n",
    "for j in range(len(total_payload)):\n",
    "    for i in range(len(total_payload[j][\"ingredients\"])):\n",
    "        pred_id = np.argmax(pred[i])\n",
    "        matched_ing = list(filter(lambda x: x[1] == pred_id,instance_cache.get_ingredients()))[0]\n",
    "        total_payload[j][\"ingredients\"][i] = [total_payload[j][\"ingredients\"][i],matched_ing[0],pred_id]\n",
    "\n",
    "    pprint(total_payload[j][\"ingredients\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapers.CocktailLinkScraper import CocktailLinkScraper\n",
    "cs = CocktailLinkScraper()\n",
    "\n",
    "ab = cs.alton_brown(\"scraper_working_data/ab-cocktails.html\")\n",
    "print(ab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
